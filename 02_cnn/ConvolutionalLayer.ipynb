{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Layer\n",
    "\n",
    "Convolutional layer is a feedforward layer that satisfies the following additional properties:\n",
    "* sparse connectivity - each neuron is connected with every channel of a small spatial region of the input\n",
    "* shared parameters - each neuron within layer uses the same parameters\n",
    "\n",
    "This notebook will not cover details of convolution arithmetic.\n",
    "Instead it focuses on Tensorflow's implementation and practical examples.\n",
    "For intuition behind convolutional operation, refer to the lecture slides.\n",
    "For mathematical details of convolutional operation, an excellent source would be:\n",
    "https://arxiv.org/abs/1603.07285\n",
    "\n",
    "In convolutional layers, it's very important to get a good grasp on the dimensions of inputs, filters, and outputs. To discuss dimensionality, we will use the following conventions in this notebook:\n",
    "* $ n^{[l]}_h $ - activation height of layer $l$, or of input image if $l = 0$\n",
    "* $ n^{[l]}_w $ - activation width of layer $l$, or of input image if $l = 0$\n",
    "* $ n^{[l]}_c $ - activation depth of layer $l$, or of input image if $l = 0$\n",
    "* $ f^{[l]} $ - height and width of a filter in layer $l$ (typically, the same across both dimensions}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution (1 input channel, 1 output channel)\n",
    "\n",
    "The key to understanding the relationship between dimensions of the input and of the output in a convolutional layer is to consider the basic case with 1 input and 1 output channels. Given input of shape $ n^{[l-1]}_h \\times n^{[l-1]}_w $ and filter of shape $ f^{[l]} \\times f^{[l]} $, the shape of the output of a convolution with padding $p$ and stride $s$: \n",
    "\n",
    "$ \\text{Convolution}\\big( n^{[l-1]}_h \\times n^{[l-1]}_w, f^{[l]} \\times f^{[l]} \\big) \\rightarrow n^{[l]}_h \\times n^{[l]}_w $\n",
    "\n",
    "$ n^{[l]}_h = \\big\\lfloor \\frac{n^{[l-1]}_h + p^{[l]} - f^{[l]}}{s^{[l]}} + 1 \\big\\rfloor $\n",
    "\n",
    "$ n^{[l]}_w = \\big\\lfloor \\frac{n^{[l-1]}_w + p^{[l]} - f^{[l]}}{s^{[l]}} + 1 \\big\\rfloor $\n",
    "\n",
    "In practive, padding is often specified as either valid or same. Valid padding simply means no padding at all ($p$ = 0), while same padding means as much padding as needed to keep spatial dimensions of the input and of the ouput the same. The exact size of same padding depends on the stride and the spatial dimensions of the input and of the filter. Typically, if the filter is larger, then more padding is needed to keep the spatial dimensions of the output equal to that of the input. Let's see an example of this calculation with Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# A simple wrapper function around Tensorflow convolution operation\n",
    "# that takes a single input matrix, and a single filter matrix,\n",
    "# and uses same padding and 1-stride.\n",
    "def conv_simple(input_mat, filter_mat):\n",
    "    # Desired input shape = batch, height, width, channel\n",
    "    # so we need to add 0th, and 3rd axes\n",
    "    input_mat = np.expand_dims(input_mat, 0)\n",
    "    input_mat = np.expand_dims(input_mat, 3)\n",
    "    input_tn = tf.constant(input_mat, dtype=tf.float32)\n",
    "    \n",
    "    # Desired filter shape = height, width, in, out\n",
    "    # so we need to add 2nd, and 3rd axes\n",
    "    filter_mat = np.expand_dims(filter_mat, 2)\n",
    "    filter_mat = np.expand_dims(filter_mat, 3)\n",
    "    filter_tn = tf.constant(filter_mat, dtype=tf.float32)\n",
    "\n",
    "    output_tn = tf.nn.conv2d(\n",
    "        input_tn, \n",
    "        strides=[1, 1, 1, 1], \n",
    "        padding='SAME', \n",
    "        filter=filter_tn\n",
    "    )\n",
    "    \n",
    "    with tf.Session() as s:\n",
    "        return s.run(output_tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>370</td>\n",
       "      <td>470</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>670</td>\n",
       "      <td>770</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230</td>\n",
       "      <td>260</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  370  470  210\n",
       "1  670  770  330\n",
       "2  230  260   90"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "    \n",
    "input_np = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "]\n",
    "\n",
    "filter_np = [\n",
    "    [10, 20],\n",
    "    [30, 40]\n",
    "]\n",
    "\n",
    "output = conv_simple(input_np, filter_np)\n",
    "pd.DataFrame(output[0, :, :, 0]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution (many input channels, 1 output channel)\n",
    "\n",
    "In the case of many input channels, the output dimensions are not affected, because the number of channels in the output depends on the number of channels in the filter. Given input of shape $n^{[l-1]}_h \\times n^{[l-1]}_w \\times n^{[l-1]}_c $ and filter of shape $f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_c$, the shape of the output of a convolution with padding $p$ and stride $s$: \n",
    "\n",
    "$\n",
    "\\text{Convolution} \\big( \n",
    "    n^{[l-1]}_h \\times n^{[l-1]}_w \\times n^{[l-1]}_c, \n",
    "    f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_c\n",
    "\\big) \n",
    "\\rightarrow n^{[l]}_h \\times n^{[l]}_w \n",
    "$\n",
    "\n",
    "$ n^{[l]}_h = \\big\\lfloor \\frac{n^{[l-1]}_h + p^{[l]} - f^{[l]}}{s^{[l]}} + 1 \\big\\rfloor $\n",
    "\n",
    "$ n^{[l]}_w = \\big\\lfloor \\frac{n^{[l-1]}_w + p^{[l]} - f^{[l]}}{s^{[l]}} + 1 \\big\\rfloor $\n",
    "\n",
    "Note that the third dimension of the filter has to match the number of channels in the input. When the filter is applied to the input, the input's channels are matched with the filter's channels. Products of corresponding spatial locations are added together across space and channels, which is why the output is still flat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution (many input channels, many output channels)\n",
    "\n",
    "When both input and output has many channels, the calculations are pretty similar but we calculate multiple independent activation maps, which gives depth to the activation tensor. Given input of shape $n^{[l-1]}_h \\times n^{[l-1]}_w \\times n^{[l-1]}_c $ and filter of shape $f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_c \\times n^{[l]}_c$, the shape of the output of a convolution with padding $p$ and stride $s$: \n",
    "\n",
    "$\n",
    "\\text{Convolution} \\big( \n",
    "    n^{[l-1]}_h \\times n^{[l-1]}_w \\times n^{[l-1]}_c, \n",
    "    f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_c \\times n^{[l]}_c\n",
    "\\big) \n",
    "\\rightarrow n^{[l]}_h \\times n^{[l]}_w \\times n^{[l]}_c\n",
    "$\n",
    "\n",
    "$ n^{[l]}_h = \\big\\lfloor \\frac{n^{[l-1]}_h + p^{[l]} - f^{[l]}}{s^{[l]}} + 1 \\big\\rfloor $\n",
    "\n",
    "$ n^{[l]}_w = \\big\\lfloor \\frac{n^{[l-1]}_w + p^{[l]} - f^{[l]}}{s^{[l]}} + 1 \\big\\rfloor $\n",
    "\n",
    "Note that the third dimension of the filter has to match the number of channels in the input,\n",
    "while the fourth dimension of the filter matches the number of channels in the output. \n",
    "Spatial dimensions (e.g. the first and the second dimensions) of the output are not affected by the number of channels.\n",
    "When applying the filter to the input, each activation map is calculated independently and then stacked together to produce activation volume. Simply stated, the fourth dimensions of the filter describes a collection of independent filters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
