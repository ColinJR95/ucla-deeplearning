{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this assingnment, we will be using Pandas dataframes\n",
    "# to read, transform, and store MNIST images. Make sure\n",
    "# you are familiar with its API:\n",
    "# https://pandas.pydata.org/pandas-docs/stable/\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pyarrow/pandas_compat.py:708: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels = getattr(columns, 'labels', None) or [\n",
      "/opt/conda/lib/python3.7/site-packages/pyarrow/pandas_compat.py:735: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n",
      "  return pd.MultiIndex(levels=new_levels, labels=labels, names=columns.names)\n",
      "/opt/conda/lib/python3.7/site-packages/pyarrow/pandas_compat.py:752: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels, = index.labels\n"
     ]
    }
   ],
   "source": [
    "# Enter here the Dataset ID that you have received in the spreadsheet.\n",
    "# Make sure that you use the ID that was assigned to you, \n",
    "# otherwise your submission will be graded against the wrong images.\n",
    "dataset_id = '20190930-184558_9a1692cf7e18a770c19b61a0a2e05b04'\n",
    "\n",
    "# Assignment datasets are stored in an AWS S3 bucket. The following code\n",
    "# downloads your dataset (~300MB) directly into RAM. Optionally,\n",
    "# you can save the datasets to the local disk, but that's really not required.\n",
    "prefix = f'https://ucla-deeplearning.s3-us-west-1.amazonaws.com/storage/mnist-v3/jobs/transform_repack/{dataset_id}'\n",
    "\n",
    "# These three dataframes contain clean images. Use each dataframe\n",
    "# to train, validate, and test your model, respectively.\n",
    "train_clean_X = pd.read_parquet(f'{prefix}/train_clean_X.parquet')\n",
    "validate_clean_X = pd.read_parquet(f'{prefix}/validate_clean_X.parquet')\n",
    "test_clean_X = pd.read_parquet(f'{prefix}/test_clean_X.parquet')\n",
    "\n",
    "# These dataframes are noisy versions of the dataframes above.\n",
    "train_noisy_X = pd.read_parquet(f'{prefix}/train_noisy_X.parquet')\n",
    "validate_noisy_X = pd.read_parquet(f'{prefix}/validate_noisy_X.parquet')\n",
    "test_noisy_X = pd.read_parquet(f'{prefix}/test_noisy_X.parquet')\n",
    "\n",
    "# This is the segment of the dataset that will be graded in this assignment.\n",
    "# Your model has to denoise this dataframe, and you have to submit the denoised version of this dataframe.\n",
    "score_noisy_X = pd.read_parquet(f'{prefix}/score_noisy_X.parquet')\n",
    "\n",
    "# For additional context, these are labels (e.g. digits) corresponding\n",
    "# to each image in the dataset. Use it to analyze which digits\n",
    "# your models has more or less problems with. These dataframes\n",
    "# should not be used as part of the training process itself,\n",
    "# only for post-training analysis, if you wish so.\n",
    "train_y = pd.read_parquet(f'{prefix}/train_y.parquet')\n",
    "validate_y = pd.read_parquet(f'{prefix}/validate_y.parquet')\n",
    "test_y = pd.read_parquet(f'{prefix}/test_y.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 784)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just as in the lecture slides, the input matrix\n",
    "# has row vectors that hold pixels of a single 28x28 image.\n",
    "# Note that the column vectors are individual locations on\n",
    "# the 28x28 grid, but flattened in a row-major way (28x28=784).\n",
    "train_clean_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While not strictly required for this assignment,\n",
    "# you will probably want to plot images to\n",
    "# have a visual understanding of the model's performance.\n",
    "# You can use any Python plotting library, for example:\n",
    "# https://matplotlib.org/contents.html\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe2f7a5d588>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's select a clean image from the dataset\n",
    "image_pixels = train_clean_X.iloc[4]\n",
    "\n",
    "# In order to plot an image, you need to reshape\n",
    "# the flattened array back into a 28x28 grid.\n",
    "image_pixels = image_pixels.values.reshape(28, 28)\n",
    "\n",
    "plt.imshow(image_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe2f7a6b978>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's select a noisy image from the dataset\n",
    "image_pixels = train_noisy_X.iloc[4]\n",
    "\n",
    "# In order to plot an image, you need to reshape\n",
    "# the flattened array back into a 28x28 grid.\n",
    "image_pixels = image_pixels.values.reshape(28, 28)\n",
    "\n",
    "plt.imshow(image_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "digit    1\n",
       "Name: 4, dtype: uint8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this couse, all assignments are expected to be\n",
    "# implemented with Tensorflow framework.\n",
    "# For this task, we can use its high-level Keras API:\n",
    "# https://keras.io\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# IMPORTANT: This is an example of an undercomplete autoencoder.\n",
    "# Your autoencoder has to be either sparse, denoising, or both.\n",
    "# In other words, you will probably need to tweak these lines of code.\n",
    "layers = [\n",
    "    # Encoder: 50 nodes, Exponential Linear Unit activation\n",
    "    Dense(units=50, activation='elu', input_shape=(28 * 28,)),\n",
    "    \n",
    "    # Decoder: matches the shape of the image\n",
    "    # Sigmoid activation is needed because pixel\n",
    "    # values are real numbers between 0 (black) and 1 (white).\n",
    "    Dense(units=28*28, activation='sigmoid')\n",
    "]\n",
    "\n",
    "# Sequential class is a Keras class that attaches every \n",
    "# layer's output to the next layer's input.\n",
    "# This is essentially a helper class for any feedforward networks.\n",
    "autoencoder = Sequential(layers)\n",
    "\n",
    "# Using MSE as the loss function, and Adam optimizer.\n",
    "# Other optimizers and losses (e.g. binary cross entropy) can also be used.\n",
    "autoencoder.compile(\n",
    "    optimizer=optimizers.Adam(\n",
    "        lr=0.01\n",
    "    ), \n",
    "    loss='mean_squared_error'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49000 samples, validate on 7000 samples\n",
      "Epoch 1/3\n",
      "49000/49000 [==============================] - 17s 344us/sample - loss: 0.0262 - val_loss: 0.0148\n",
      "Epoch 2/3\n",
      "49000/49000 [==============================] - 13s 272us/sample - loss: 0.0136 - val_loss: 0.0127\n",
      "Epoch 3/3\n",
      "49000/49000 [==============================] - 15s 299us/sample - loss: 0.0115 - val_loss: 0.0109\n"
     ]
    }
   ],
   "source": [
    "# In order to have reproducible results, we need\n",
    "# to set the seed values for NumPy and Tensorflow.\n",
    "# Keep these lines in the same cell as the training code,\n",
    "# so that you don't accidentally train multiples models\n",
    "# without reseting the seed.\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "np.random.seed(11)\n",
    "tf.random.set_random_seed(11)\n",
    "\n",
    "# IMPORTANT: This is an example of an undercomplete autoencoder.\n",
    "# Your autoencoder has to be either sparse, denoising, or both.\n",
    "# In other words, you will probably need to tweak these lines of code.\n",
    "history = autoencoder.fit(\n",
    "    x=train_clean_X, \n",
    "    y=train_clean_X, \n",
    "    \n",
    "    # It's a good idea to have low number of epochs,\n",
    "    # to test the learning process, but not for the final model training.\n",
    "    epochs=3,\n",
    "    \n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    validation_data=(validate_clean_X, validate_clean_X)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.02617090145133588, 0.013589700905340058, 0.01148502149341666],\n",
       " 'val_loss': [0.01479419984029872, 0.012711292267910072, 0.010871851823159627]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to take a look at the learning curve,\n",
    "# you can plot it using the following dictionary.\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can feed the noisy images into the autoencoder.\n",
    "train_denoised_X = autoencoder.predict(train_noisy_X)\n",
    "\n",
    "# Keras returns back a Numpy array, but we need Pandas dataframe,\n",
    "# so let's quickly put the denoised images into a dataframe.\n",
    "train_denoised_X = pd.DataFrame(train_denoised_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's confirm that the denoiser works.\n",
    "image_pixels = train_denoised_X.iloc[4]\n",
    "\n",
    "# In order to plot an image, you need to reshape\n",
    "# the array into a 28x28 grid.\n",
    "image_pixels = image_pixels.values.reshape(28, 28)\n",
    "\n",
    "plt.imshow(image_pixels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016721239458014583"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To calculate MSE between two datasets we can use scikit-learn:\n",
    "# https://scikit-learn.org/stable/\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# This calcualates MSE on train clean against train denoised,\n",
    "# which measures how well the autoencoder denoises the training dataset.\n",
    "# Note that you really want to calculate this metric on validate and/or test dataset.\n",
    "# Don't let an overfitting model fool you into using it for the graded submission!\n",
    "mean_squared_error(train_denoised_X, train_clean_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pyarrow/pandas_compat.py:114: FutureWarning: A future version of pandas will default to `skipna=True`. To silence this warning, pass `skipna=True|False` explicitly.\n",
      "  result = infer_dtype(pandas_collection)\n"
     ]
    }
   ],
   "source": [
    "# Once you are ready to make the graded submission,\n",
    "# run the autoencoder on the score noisy dataset.\n",
    "score_denoised_X = pd.DataFrame(\n",
    "    autoencoder.predict(score_noisy_X),\n",
    "    # This is needed to save the file in Parquet format.\n",
    "    columns=score_noisy_X.columns\n",
    ")\n",
    "\n",
    "# Now save it to disc as a Parquet file.\n",
    "score_denoised_X.to_parquet('score_denoised_X.parquet')\n",
    "\n",
    "# Next, let's save the model's definition.\n",
    "import json\n",
    "with open(f'keras_model.json', 'w') as f:\n",
    "    f.write(json.dumps(json.loads(autoencoder.to_json()), indent=True))\n",
    "\n",
    "# Finally, let's save the learned parameters.\n",
    "autoencoder.save_weights(f\"keras_parameters.h5\")\n",
    "\n",
    "# You now have the following files to be uploaded to Moodle:\n",
    "# 1. This notebook and any other Python code you used to train the final model.\n",
    "# 2. keras_model.json -- the model's definition\n",
    "# 3. keras_parameters.json -- the model's trained parameters\n",
    "# 4. score_denoised_X.parquet - the model's output on the score dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
